---
title: 'CKME136 Capstone Project'
author: "Erma Fernando (Student Number 500925471)"
output:
  word_document: default
  pdf_document: default
  
---
# Load Data
### 1. Read the csv files for 2011, 2012, 2013, 1014, 2015
```{r}
#data2011<-read.csv(file="C:/RY/CKME136/OntarioGHG data/ModifiedData/bps_raw_2011_modified.csv",header=T,sep=",")
"C:/RY/CKME136/Coding"
data2011<-read.csv(file="C:/RY/CKME136/OntarioGHG data/FinalData/bps_raw_2011_modified_20181113.csv",header=T,sep=",")

#data2012<-read.csv(file="C:/RY/CKME136/OntarioGHG #data/FinalData/bps_raw_2011_modified_20181105.csv",header=T,sep=",")
#data2013<-read.csv(file="C:/RY/CKME136/OntarioGHG #data/FinalData/bps_raw_2011_modified_20181105.csv",header=T,sep=",")
#data2014<-read.csv(file="C:/RY/CKME136/OntarioGHG #data/FinalData/bps_raw_2011_modified_20181105.csv",header=T,sep=",")
#data2015<-read.csv(file="C:/RY/CKME136/OntarioGHG #data/FinalData/bps_raw_2011_modified_20181105.csv",header=T,sep=",")

### 2. Merge the data frames for 2011, 2012, 2013, 1014, 2015
# all_data <-(rbind(data2011, data2012, data2013, data2014, data 2015)

```

# Load packages - packages stored in C:\software\packages set env variable R_LIBS_USER

```{r}
install.packages("dplyr")
library(dplyr)
install.packages("colorspace", repos="http://R-Forge.R-project.org")
install.packages("ggplot2")
library(ggplot2)
install.packages("corrplot")
library(corrplot)
install.packages("reshape2")
library(reshape2)

```
# Initial Analysis of the data

```{r}
# column headers
names(data2011)
str(data2011)
# 18734 rows 29 columns
head(data2011)
# min, max, median, mean 1st quartile, 3rd quartile
summary(data2011)
# Rows with missing data - none - because all replaced with 0 before csv load
sapply(data2011, function(x) sum(is.na(x)))
# data2011[!complete.cases(data2011),]
# count of various data types -factor 6 integer 3 logical 2  numeric 18
table(unlist(lapply(data2011,class)))
#list the unique values in variable "OperationType""
sapply(data2011, function(x) unique(data2011$OperationType))


```
# Exploratory phase - Box plots, histograms, Look for outliers
```{r}
summary(data2011$GHGEmissions.Kg)
#GHG starts from min=0 to max 5452000000 with median 3474)
hist (data2011$GHGEmissions.Kg[data2011$GHGEmissions.Kg<3474], main='Histogram of GHG<3474')
hist (data2011$GHGEmissions.Kg[data2011$GHGEmissions.Kg >3474], main='Histogram of GHG>3474')
summary(data2011$Electricity.kwh)
#Electricity starts from min=0 to max 5452000000 with median 101300)
hist (data2011$Electricity.kwh[data2011$Electricity.kwh<101300], main='Histogram of Electricity <101300')
hist (data2011$Electricity.kwh[data2011$Electricity.kwh >101300], main='Histogram of Electricity >101300')
hist(data2011$NaturalGas.Cubicmeter, main='Histogram of Gas')
hist(data2011$FloorArea.Sqft, main='Histogram of Floor Area')
hist(data2011$GHGEmissions.Kg, main='Histogram of GHG emisssions')

boxplot(data2011$GHGEmissions.Kg, main='Boxplot of GHG emisssions')

# listthe outliers (results show many outliers)
boxplot.stats(data2011$GHGEmissions.Kg)$out

p<-ggplot(data2011, aes( data2011$GHGEmissions.Kg, data2011$OperationType))

geom_boxplot(mapping = NULL, data = NULL, stat = "boxplot",
  position = "dodge2",data2011, outlier.colour = NULL,
  outlier.color = NULL, outlier.fill = NULL, outlier.shape = 19,
  outlier.size = 1.5, outlier.stroke = 0.5, outlier.alpha = NULL,
  notch = FALSE, notchwidth = 0.5, varwidth = FALSE, na.rm = FALSE,
  show.legend = NA, inherit.aes = TRUE)

p + geom_boxplot()

# using log scale for GHG - blue shows the outliers
ggplot(data = data2011, aes(x=data2011$OperationType, y=data2011$GHGEmissions.Kg)) + 
            scale_y_log10() +
            geom_point(aes(color=data2011$OperationType), alpha=0.2) +
            geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)



```
# Exploratory phase 
```{r}
#install.packages("tidyverse")
#detach("package:plyr", unload=TRUE) 
#detach("package:Rmisc", unload=TRUE) 
#library(dplyr)

#create table of counts of records for each OperationType arrange by descending counts

data2011 %>%
summarise(freq=n(), GHGEmissions.Kg=sum(GHGEmissions.Kg)) %>%
group_by(OperationType) %>%
arrange(desc(freq))

#create table of counts of records for each OperationType arrange by descending GHGEmissions.Kg

data2011 %>%
group_by(OperationType) %>%
summarise(freq=n(), totalGHG=sum(GHGEmissions.Kg)) %>%
arrange(desc(totalGHG))

#create table of distinct OperationType

data2011 %>%
distinct(OperationType)


```

# Exploratory phase 

# Split the data into 2 - Operation Types reporting GHG per area (15566 rows) and those reporting GHG per volume (3168 rows)
# Then Normalize the data

```{r}


data2011_area<-subset(data2011, data2011$FloorArea.Sqft>0)  
data2011_volume<-subset(data2011, data2011$FloorArea.Sqft==0) 

x<-NROW(data2011_area)
x
y<-NROW(data2011_volume)
y
normalize <- function(x){
  return ((x-min(x))/(max(x) - min(x)))
}

# normalize numerical columns (remove non-numerical columns)
summary(data2011_area)
data2011_area_n <-as.data.frame(lapply(data2011_area[,-c(1:7)], normalize))
data2011_volume_n <-as.data.frame(lapply(data2011_volume[,-c(1:7)], normalize))
summary(data2011_area_n)
summary(data2011_volume_n)

# combine normalized numerical columns with non-numerical columns that were removed
data2011_area_n2 <-cbind(data2011_area[,c(1:7)],(data2011_area_n))
summary(data2011_area_n2)

data2011_volume_n2 <-cbind(data2011_volume[,c(1:7)],(data2011_volume_n))
summary(data2011_volume_n2)
```
# Exploratory phase

#Correlation between the numerical attributes in normalized data.  Plot the data.
```{r}
correlations_area <-cor(data2011_area_n, method = "spearman", use = "pairwise.complete.obs") 
correlations_area
summary(correlations_area)

correlations_volume <-cor(data2011_volume_n, method = "spearman", use = "pairwise.complete.obs") 
correlations_volume
summary(correlations_volume)


corrplot(correlations_area, method="circle")
corrplot(correlations_volume, method="circle")


#p <- ggplot(data2011_area_n, aes(x=data2011_area_n$GHG.Emissions.Kg., y=data2011_area_n$Electricity.kwh)) + 
  geom_boxplot()


plot(x=data2011_area_n2$Electricity, y=data2011_area_n2$GHG.Emissions.Kg.)
mean_ghg<-mean(data2011_area_n2$GHG.Emissions.Kg.)
max_ghg <-max(data2011_area_n2$GHG.Emissions.Kg.)
min_ghg<-min(data2011_area_n2$GHG.Emissions.Kg.)
sd_ghg<-sd(data2011_area_n2$GHG.Emissions.Kg.)
mean_ghg
min_ghg
max_ghg
sd_ghg

```


```
Prediction Stage

# Divide the normalized data into training and testing groups 70:30

```{r}

train_index <-sample (1:nrow(data2011_area_n2), 0.7*nrow(data2011_area_n2))
train.set <- data2011_area_n2[train_index,]
test.set <- data2011_area_n2[-train_index,]
```

MultivariateLinear Regression model

```{r}
  model_mlr_area <- lm(train.set $GHGEmissions.Kg ~train.set $Electricity.kwh +train.set $NaturalGas.Cubicmeter+train.set $DistrictHeat+train.set $DistrictCool+train.set $FuelOil1.2, data=train.set) 
summary(model_mlr_area)
coefficients(model_mlr_area)
aov(model_mlr_area)
prediction <- predict(model_mlr_area, interval="prediction", newdata =test.set)


```

Look at errors and plot them on a histogram. 
```{r}
errors <- prediction[,"fit"] - test.set$GHGEmissions.Kg
hist(errors)

```
. 
Compute the root mean square error and find the percentage of cases with less than 25% error.
```{r}
rmse <- sqrt(sum((prediction[,"fit"] - data2011_area_n2$GHGEmissions.Kg)^2)/nrow(test.set))
rel_change <- 1 - ((test.set$GHGEmissions.Kg - abs(errors)) / test.set$GHGEmissions.Kg)
pred25 <- table(rel_change<0.25)["TRUE"] / nrow(test.set)
paste("RMSE:", rmse)
paste("PRED(25):", pred25)
```

Dimensionality Reduction

Use the forward selection algorithm. We will start with 'null', which means none of the independent variables are selected. We will come up with a selection of independent variables between 'null' and 'full'. 'full' means all the independent variables are included. Do we end up using all the variables. We set 'trace=TRUE' to see all the steps.
```{r echo=TRUE}
library(MASS)
full <- lm(data2011_area_n2$GHGEmissions.Kg ~ data2011_area_n2$Electricity + data2011_area_n2$NaturalGas.Cubicmeter +data2011_area_n2$Propane+data2011_area_n2$Propane +data2011_area_n2$DistrictHeat +data2011_area_n2$DistrictCool +data2011_area_n2$FuelOil1.2, data=data2011_area_n2)
null <- lm(data2011_area_n2$GHGEmissions.Kg~1,data=data2011_area_n2)
stepF <- stepAIC(null, scope=list(lower=null, upper=full), direction= "forward", trace=TRUE)

#display results]
summary(stepF)
stepF$anova

```

 Use nls package for non-linear regression
```{r}

#nls(formula, data, start)
#nonlin_Mod<-nls(y~data2011$Electricity, data2011, start=1000)
#nonlin_Mod<-nls(y~data2011$Electricity, data2011, start=1000)



`

